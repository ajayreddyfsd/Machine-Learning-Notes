{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e2bb5a-b339-49f5-ab5c-012644fae669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551dfd97-25c8-4bf0-9cc2-9fa0af2305e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['sex', 'embarked']\n",
      "Numeric Columns: ['pclass', 'age', 'sibsp', 'parch', 'fare', 'adult_male', 'alone']\n",
      "\n",
      "✅ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       105\n",
      "           1       0.80      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')  # For clean output\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=['survived'])\n",
    "\n",
    "# Target and features\n",
    "X = df.drop(columns=['survived'])\n",
    "y = df['survived']\n",
    "\n",
    "# Drop high-cardinality or unneeded cols\n",
    "X = X.drop(columns=['embark_town', 'deck', 'alive', 'who', 'class'])\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number', 'bool']).columns.tolist()\n",
    "\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "print(\"Numeric Columns:\", numeric_cols)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1️⃣ Numeric Pipeline: Impute + Scale\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2️⃣ Categorical Pipeline: Impute + One-Hot Encode\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 3️⃣ Combine using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_pipeline, numeric_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4️⃣ Final Pipeline: Preprocessor + Model\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf_pipeline.predict(X_test)\n",
    "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8669afa-4cd7-4763-bbee-ab5a54fcf363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "✅ Best Parameters:\n",
      "{'classifier__max_depth': 5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid (prefix with 'classifier__')\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [5, 10, None],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(clf_pipeline, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Results\n",
    "print(\"\\n✅ Best Parameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a373a1-cbb1-4c44-8162-b3fd22f9f887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
